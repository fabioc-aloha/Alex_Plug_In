# Alex VS Code Extension â†’ v4.0.0 QUADRUNIUM Roadmap

> **Epistemic Integrity: Calibrated Confidence & Appropriate Reliance**

| | |
|---|---|
| **Target Version** | 4.0.0 QUADRUNIUM |
| **Codename** | ğŸ›¡ï¸ **Trust** (Epistemic Integrity) |
| **Status** | ğŸ“‹ Planning |
| **Prerequisite** | v3.5.0 TRITRSEPTIUM-PENT-HEX (Transition Release) |
| **Foundation** | v3.4.3 TRITRSEPTIUM-PENT (Current) |
| **Created** | 2026-01-29 |
| **Author** | Alex Cognitive Architecture Team |

> **Note:** See [ROADMAP-VSCODE-V3.5.md](ROADMAP-VSCODE-V3.5.md) for the transition release that must ship first.

---

## ğŸ¯ Vision: Trustworthy AI Partnership

Version 4.0 represents a **paradigm shift** in how Alex operates. Building on the comprehensive research synthesis documented in `article/appropriate-reliance/APPROPRIATE-RELIANCE-V5.md`, this release implements:

1. **Calibrated Confidence** â€” Express uncertainty proportional to actual reliability
2. **Appropriate Reliance** â€” Help users accept correct outputs and reject incorrect ones
3. **Creative Latitude** â€” Preserve AI creativity while maintaining epistemic integrity
4. **Verification Facilitation** â€” Help users verify when they choose to, without forcing it

> "Appropriate reliance occurs when users accept correct AI outputs and reject incorrect ones."
> â€” AETHER Research Synthesis (Passi et al., 2024)

### Why This Matters

The AETHER synthesis of ~50 papers reveals that inappropriate reliance causes:
- **Poor team performance** â€” Human+AI teams can perform *worse* than either alone
- **Ineffective oversight** â€” Over-reliance undermines safety mechanisms
- **Product abandonment** â€” Incorrect mental models erode trust over time

Alex 4.0 addresses these challenges through architectural implementation of research-validated mitigation strategies.

---

## ğŸ“‹ Implementation Tracker

### âœ… Foundation Complete (v3.4.x)

| # | Feature | Status | Description |
|:-:|---------|:------:|-------------|
| - | @alex Chat Participant | âœ… | 16 slash commands |
| - | Language Model Tools | âœ… | 11 tools (synapse_health, memory_search, etc.) |
| - | Global Knowledge System | âœ… | search, save, promote, status |
| - | Cloud Sync | âœ… | GitHub Gists backup |
| - | Status Bar Health | âœ… | ğŸŸ¢/ğŸŸ¡/ğŸ”´ visual indicator |
| - | Context Menu Actions | âœ… | Right-click: Save, Ask, Search |
| - | Knowledge Quick Pick | âœ… | Ctrl+Shift+K search |
| - | Session Timer | âœ… | Pomodoro with goal tracking |
| - | Welcome View | âœ… | Activity bar panel |
| - | Learning Goals | âœ… | Daily/weekly tracking |
| - | Auto-Insights | âœ… | Pattern detection |
| - | Health Dashboard | âœ… | Rich webview visualization |

### v4.0.0 Core: Epistemic Integrity Framework

| # | Feature | Status | Effort | Description |
|:-:|---------|:------:|:------:|-------------|
| 1 | Confidence Calibration System | â¬œ | 2d | Four-tier source grounding with calibrated expression |
| 2 | Confidence Ceiling Protocol | â¬œ | 1d | 90% max for generated content, 70% for unsourced facts |
| 3 | "Confident But Wrong" Detection | â¬œ | 2d | Heuristics for misconceptions, outdated info, biases |
| 4 | Category vs. Individual Distinction | â¬œ | 1d | Pattern-level vs. specific-claim confidence |
| 5 | Self-Correction Protocol | â¬œ | 1d | Graceful error acknowledgment without over-apologizing |

### v4.0.0 Mitigation Strategies (AETHER-Validated)

| # | Feature | Status | Effort | Description |
|:-:|---------|:------:|:------:|-------------|
| 6 | Verification-Focused Explanations | â¬œ | 2d | Self-critiques, contrastive framing, background info |
| 7 | Uncertainty Expression System | â¬œ | 2d | Linguistic + code comment uncertainty indicators |
| 8 | Cognitive Forcing Functions | â¬œ | 2d | Strategic questioning for high-stakes decisions |
| 9 | Scaffolded Assistance Protocol | â¬œ | 1d | Adapt support level based on user expertise |

### v4.0.0 Creative Latitude Framework

| # | Feature | Status | Effort | Description |
|:-:|---------|:------:|:------:|-------------|
| 10 | Epistemic vs. Generative Mode | â¬œ | 1d | Different protocols for facts vs. creative contributions |
| 11 | Collaborative Validation Protocol | â¬œ | 1d | Joint evaluation of novel ideas |
| 12 | Agreement-Seeking Patterns | â¬œ | 1d | "Here's an unconventional ideaâ€”does it resonate?" |

### v4.0.0 Human Agency Preservation

| # | Feature | Status | Effort | Description |
|:-:|---------|:------:|:------:|-------------|
| 13 | Agency-Preserving Language | â¬œ | 1d | "Here's one approach..." not "You should..." |
| 14 | Human Judgment Flagging | â¬œ | 1d | Flag domains requiring human decision |
| 15 | Skill Development Support | â¬œ | 1d | Encourage learning, not just task completion |

### v4.0.0 Measurement & Validation

| # | Feature | Status | Effort | Description |
|:-:|---------|:------:|:------:|-------------|
| 16 | CAIR/CSR Metrics Integration | â¬œ | 2d | Track correct AI-reliance and correct self-reliance |
| 17 | Reliance Pattern Analytics | â¬œ | 2d | Dashboard showing user reliance behaviors |
| 18 | Calibration Quality Tracking | â¬œ | 1d | Measure alignment between confidence and correctness |

### v4.0.0 Architecture Updates

| # | Feature | Status | Effort | Description |
|:-:|---------|:------:|:------:|-------------|
| 19 | DK-APPROPRIATE-RELIANCE v2.0 | â¬œ | 1d | Enhanced domain knowledge with AETHER integration |
| 20 | Protocol Triggers Update | â¬œ | 1d | New triggers for confidence, verification, CFFs |
| 21 | Synapse Network Enhancement | â¬œ | 1d | New synapses for epistemic integrity pathways |
| 22 | User Profile Epistemic Settings | â¬œ | 1d | Preferences for uncertainty expression style |

### Carried Over from v3.5+ Planning

| # | Feature | Status | Effort | Description |
|:-:|---------|:------:|:------:|-------------|
| 23 | Test-Driven Learning | â¬œ | 3d | Interactive learning with test watching |
| 24 | Code Review Assist | â¬œ | 3d | PR analysis with knowledge correlation |
| 25 | Debug Memory | â¬œ | 2d | Context-aware debugging with knowledge |
| 26 | Goal Sessions | â¬œ | 2d | Focused work mode with auto-tracking |

### Prerequisites from v3.5.0 (Must Ship First)

> The following features will be implemented in v3.5.0 and are prerequisites for v4.0.0.
> See [ROADMAP-VSCODE-V3.5.md](ROADMAP-VSCODE-V3.5.md) for full details.

| # | Feature | v3.5 Status | Description |
|:-:|---------|:----------:|-------------|
| - | Configurable Storage Paths | â¬œ | User-configurable global knowledge location |
| - | Agent Skills Validation | â¬œ | Verify Alex skills format matches VS Code 1.108 spec |
| - | Tool Annotations | â¬œ | Add readOnlyHint to read-only tools |
| - | Participant Detection | â¬œ | Auto-route epistemic queries via disambiguation |
| - | Follow-up Provider | â¬œ | Suggest contextual follow-up questions |
| - | Tool Confirmation Messages | â¬œ | Custom confirmation dialogs |
| - | `/forget <topic>` Command | â¬œ | Selective memory cleanup |
| - | Webview HTML Sanitization | â¬œ | Security hardening |

**Legend:** â¬œ Not Started | ğŸ”„ In Progress | âœ… Complete

**v4.0.0 Core Tasks: 0/26 complete** (excludes v3.5 prerequisites)

---

## ğŸ¯ Feature Specifications

### 1. Confidence Calibration System

**Goal:** Map internal uncertainty signals to external confidence expressions

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FOUR-TIER SOURCE GROUNDING                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  TIER 1: DOCUMENTED                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Source: Files in context, user-provided documents               â”‚   â”‚
â”‚  â”‚ Pattern: "The codebase shows...", "According to the file..."    â”‚   â”‚
â”‚  â”‚ Confidence: Up to 100%                                          â”‚   â”‚
â”‚  â”‚ Verification: Low â€” user can readily confirm                    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                         â”‚
â”‚  TIER 2: INFERRED                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Source: Logical deduction from documented sources               â”‚   â”‚
â”‚  â”‚ Pattern: "Based on the pattern...", "This suggests..."          â”‚   â”‚
â”‚  â”‚ Confidence: Up to 80%                                           â”‚   â”‚
â”‚  â”‚ Verification: Medium â€” inference may have assumptions           â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                         â”‚
â”‚  TIER 3: UNCERTAIN                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Source: Edge cases, version-specific, potentially outdated      â”‚   â”‚
â”‚  â”‚ Pattern: "I'm not certain, but...", "You may want to verify..." â”‚   â”‚
â”‚  â”‚ Confidence: Up to 50%                                           â”‚   â”‚
â”‚  â”‚ Verification: High â€” treat as hypothesis                        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                         â”‚
â”‚  TIER 4: UNKNOWN                                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Source: Private data, recent events, real-time info needed      â”‚   â”‚
â”‚  â”‚ Pattern: "I don't have information about...", "You'd need to..."â”‚   â”‚
â”‚  â”‚ Confidence: 0% â€” cannot reliably know                           â”‚   â”‚
â”‚  â”‚ Verification: Required â€” not optional                           â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Implementation Files:**
- `src/shared/confidence/calibration.ts` â€” Core calibration logic
- `src/shared/confidence/sourceGrounding.ts` â€” Tier classification
- `src/shared/confidence/languagePatterns.ts` â€” Expression templates

---

### 2. Confidence Ceiling Protocol

**Research Basis:** Lin et al. (2022), AETHER synthesis (Mielke et al., 2022)

**Principle:** Generated content should never claim absolute certainty.

| Content Type | Maximum Confidence | Rationale |
|--------------|-------------------|-----------|
| Direct file reading | 100% | User can verify against source |
| Code from documented patterns | 90% | "Should work, but verify" |
| Factual claims without source | 70% | Training data may be incomplete |
| Inference or edge cases | 50% | Multiple unknowns compound |

**Language Mapping:**
```typescript
const confidenceExpressions = {
  high: ["Based on the documentation...", "The code shows..."],
  medium: ["Generally...", "In most cases...", "Typically..."],
  low: ["I believe...", "If I recall correctly...", "I'm not certain, but..."],
  unknown: ["I don't have reliable information about...", "You'd need to check..."]
};
```

---

### 3. "Confident But Wrong" Detection

**Research Basis:** TMLR reviewer mS55 critique, AETHER synthesis

**Problem Categories:**

| Category | Risk Signal | Detection Heuristic | Response |
|----------|-------------|---------------------|----------|
| **Common misconceptions** | Claims stated as "everyone knows" | No authoritative source | Downgrade + verify |
| **Outdated information** | Time-sensitive claims | Versions, leadership, standards | Temporal uncertainty |
| **Fictional bleed** | Extraordinary claims | Pop culture "facts" | Require citation |
| **Social biases** | Group generalizations | Stereotypes as patterns | Apply extra scrutiny |

**Implementation:**
```typescript
interface ConfidentButWrongDetector {
  detectMisconception(claim: string): RiskAssessment;
  detectOutdated(claim: string, domain: string): TemporalRisk;
  detectFictionalBleed(claim: string): boolean;
  detectBias(claim: string): BiasRisk;
}
```

---

### 6. Verification-Focused Explanations

**Research Basis:** AETHER synthesis (Fok & Weld, 2023; Saunders et al., 2022)

**Types:**

| Type | Purpose | Example |
|------|---------|---------|
| **Self-critique** | Identify potential weaknesses | "One potential issue: this assumes the API is synchronous" |
| **Contrastive** | Show both supporting and refuting evidence | "Some sources suggest A, but others indicate B" |
| **Background** | Provide verification context | "My knowledge is based on [source]. Given rapid changes, checking current docs is wise" |

**Caveat Implementation:** Per AETHER finding that explanations can backfire:
- Don't over-explain in ways that increase false confidence
- Flag when explanations themselves are uncertain

---

### 8. Cognitive Forcing Functions

**Research Basis:** BuÃ§inca et al. (2021), AETHER synthesis

**Strategic Application:** CFFs are applied selectively to avoid cognitive burden.

| Trigger | CFF Type | Example |
|---------|----------|---------|
| High-stakes domain | Strategic question | "Before implementing this security approach, what threat model assumptions does this rely on?" |
| Critical code path | Verification prompt | "This handles the happy path. For production: What if the service is unavailable?" |
| Multi-turn opportunity | Elaboration invitation | "This is my initial suggestion. Want to walk through edge cases together?" |

**Calibration:** Apply based on:
- Claim uncertainty level (higher uncertainty â†’ more likely CFF)
- Potential consequence of error (higher stakes â†’ more likely CFF)
- User expertise level (novice â†’ more support; expert â†’ lighter touch)
- Task type (security, financial â†’ more scrutiny)

---

### 10. Epistemic vs. Generative Mode

**Principle:** Different protocols for facts vs. creative contributions

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DUAL-MODE OPERATION                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  EPISTEMIC MODE                    â”‚  GENERATIVE MODE                   â”‚
â”‚  (Facts, established knowledge)    â”‚  (Creative, novel ideas)           â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚                                    â”‚                                    â”‚
â”‚  â€¢ Full calibration protocols      â”‚  â€¢ Frame as proposal, not fact     â”‚
â”‚  â€¢ Source grounding required       â”‚  â€¢ Invite collaborative validation â”‚
â”‚  â€¢ Confidence ceiling enforced     â”‚  â€¢ Welcome refinement              â”‚
â”‚  â€¢ Verification facilitation       â”‚  â€¢ Distinguish novelty from        â”‚
â”‚                                    â”‚    uncertainty                     â”‚
â”‚                                    â”‚                                    â”‚
â”‚  "The documentation states..."     â”‚  "Here's an idea worth             â”‚
â”‚  "According to the codebase..."    â”‚   considering..."                  â”‚
â”‚  "This is established pattern..."  â”‚  "What do you think about...?"     â”‚
â”‚                                    â”‚                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### 16. CAIR/CSR Metrics Integration

**Research Basis:** Schemmer et al. (2023), AETHER synthesis

**Definitions:**
- **CAIR (Correct AI-Reliance):** User accepts AI output when AI is correct
- **CSR (Correct Self-Reliance):** User rejects AI output when AI is wrong
- **AoR (Appropriateness of Reliance):** Combined metric (AoR = 1 is optimal)

**Measurement Matrix:**

|                      | User accepts | User rejects |
|----------------------|--------------|--------------|
| AI output correct    | CAIR âœ…      | Under-reliance âš ï¸ |
| AI output incorrect  | Over-reliance âš ï¸ | CSR âœ… |

**Dashboard Integration:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ“Š RELIANCE ANALYTICS                                                  â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚                                                                         â”‚
â”‚  Appropriateness of Reliance (AoR)                                      â”‚
â”‚  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  0.73 / 1.00                        â”‚
â”‚                                                                         â”‚
â”‚  CAIR (Correct AI-Reliance)         CSR (Correct Self-Reliance)        â”‚
â”‚  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘  85%   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  61%  â”‚
â”‚                                                                         â”‚
â”‚  Insight: Users tend to accept correct outputs but could improve at    â”‚
â”‚  rejecting incorrect ones. Consider enabling more CFFs.                â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Architecture Changes

### New Files

| File | Purpose |
|------|---------|
| `src/shared/confidence/` | Confidence calibration module |
| `src/shared/confidence/calibration.ts` | Core calibration logic |
| `src/shared/confidence/sourceGrounding.ts` | Four-tier source classification |
| `src/shared/confidence/ceilings.ts` | Confidence ceiling enforcement |
| `src/shared/confidence/detection.ts` | "Confident but wrong" detection |
| `src/shared/mitigation/` | AETHER mitigation strategies |
| `src/shared/mitigation/explanations.ts` | Verification-focused explanations |
| `src/shared/mitigation/uncertainty.ts` | Uncertainty expression system |
| `src/shared/mitigation/cff.ts` | Cognitive forcing functions |
| `src/shared/reliance/` | Reliance measurement |
| `src/shared/reliance/metrics.ts` | CAIR/CSR tracking |
| `src/shared/reliance/analytics.ts` | Reliance pattern analysis |
| `src/views/relianceAnalytics.ts` | Dashboard webview |

### Modified Files

| File | Changes |
|------|---------|
| `package.json` | New settings for epistemic preferences |
| `src/extension.ts` | Confidence system initialization |
| `src/chat/chatHandler.ts` | Integrate calibration into responses |
| `src/shared/languageModel.ts` | Add confidence metadata to outputs |
| `.github/domain-knowledge/DK-APPROPRIATE-RELIANCE.md` | v2.0 with AETHER integration |
| `.github/instructions/protocol-triggers.instructions.md` | New epistemic triggers |

### New Settings

```json
{
  "alex.epistemic.confidenceCeiling": {
    "type": "boolean",
    "default": true,
    "description": "Apply 90% confidence ceiling to generated content"
  },
  "alex.epistemic.uncertaintyStyle": {
    "type": "string",
    "enum": ["minimal", "balanced", "explicit"],
    "default": "balanced",
    "description": "How verbosely to express uncertainty"
  },
  "alex.epistemic.cffFrequency": {
    "type": "string",
    "enum": ["minimal", "moderate", "frequent"],
    "default": "moderate",
    "description": "How often to apply cognitive forcing functions"
  },
  "alex.epistemic.trackReliance": {
    "type": "boolean",
    "default": false,
    "description": "Track CAIR/CSR metrics (requires user consent)"
  }
}
```

---

## ğŸ“… Implementation Schedule

### Phase 1: Core Epistemic Framework (Week 1-2)

| Day | Task | Output |
|-----|------|--------|
| 1-2 | Confidence Calibration System | Feature #1 complete |
| 3 | Confidence Ceiling Protocol | Feature #2 complete |
| 4-5 | "Confident But Wrong" Detection | Feature #3 complete |
| 6 | Category vs. Individual Distinction | Feature #4 complete |
| 7 | Self-Correction Protocol | Feature #5 complete |
| 8 | Integration testing | Core framework tested |

### Phase 2: Mitigation Strategies (Week 3)

| Day | Task | Output |
|-----|------|--------|
| 9-10 | Verification-Focused Explanations | Feature #6 complete |
| 11-12 | Uncertainty Expression System | Feature #7 complete |
| 13-14 | Cognitive Forcing Functions | Feature #8 complete |
| 15 | Scaffolded Assistance Protocol | Feature #9 complete |

### Phase 3: Creative Latitude & Agency (Week 4)

| Day | Task | Output |
|-----|------|--------|
| 16 | Epistemic vs. Generative Mode | Feature #10 complete |
| 17 | Collaborative Validation Protocol | Feature #11 complete |
| 18 | Agreement-Seeking Patterns | Feature #12 complete |
| 19 | Agency-Preserving Language | Feature #13 complete |
| 20 | Human Judgment Flagging | Feature #14 complete |
| 21 | Skill Development Support | Feature #15 complete |

### Phase 4: Measurement & Polish (Week 5)

| Day | Task | Output |
|-----|------|--------|
| 22-23 | CAIR/CSR Metrics Integration | Feature #16 complete |
| 24-25 | Reliance Pattern Analytics | Feature #17 complete |
| 26 | Calibration Quality Tracking | Feature #18 complete |
| 27-28 | Documentation & release prep | v4.0.0 ready |

### Phase 5: Deferred Features (Post-Release)

Features #23-26 (Test-Driven Learning, Code Review Assist, Debug Memory, Goal Sessions) deferred to v4.1.x to maintain focus on epistemic integrity.

---

## ğŸ§ª Testing Strategy

### Unit Tests

| Module | Test Coverage |
|--------|---------------|
| Confidence calibration | Tier classification accuracy |
| Ceiling enforcement | Never exceeds maximum |
| Detection heuristics | False positive/negative rates |
| CFF application | Correct trigger conditions |

### Integration Tests

| Scenario | Validation |
|----------|------------|
| File reading | Tier 1 confidence, 100% max |
| Code generation | Tier 2 confidence, 90% ceiling |
| Uncertain domain | Tier 3 language patterns |
| Unknown query | Tier 4 acknowledgment |
| Error correction | Self-correction protocol fires |
| Creative suggestion | Generative mode, collaborative validation |

### User Acceptance

| Metric | Target |
|--------|--------|
| Confidence expression naturalness | User survey â‰¥ 4/5 |
| Uncertainty helpfulness | Users find it aids decisions |
| CFF acceptability | Not perceived as annoying |
| Creative latitude preservation | AI still feels collaborative |

---

## ğŸ“Š Success Metrics

| Metric | Target | Measurement |
|--------|--------|-------------|
| CAIR (Correct AI-Reliance) | â‰¥ 85% | User accepts correct outputs |
| CSR (Correct Self-Reliance) | â‰¥ 70% | User rejects incorrect outputs |
| AoR (Appropriateness of Reliance) | â‰¥ 0.75 | Combined metric |
| Confidence-correctness correlation | r â‰¥ 0.7 | Higher confidence â†’ higher accuracy |
| User satisfaction with uncertainty | â‰¥ 4/5 | Survey rating |
| Creative engagement preserved | No decrease | Compared to v3.4 baseline |

---

## ğŸ”— Related Documents

- [article/appropriate-reliance/APPROPRIATE-RELIANCE-V5.md](article/appropriate-reliance/APPROPRIATE-RELIANCE-V5.md) â€” Comprehensive scholarly treatment
- [article/appropriate-reliance/](article/appropriate-reliance/) â€” Research artifacts (AETHER PDF, NFW Report, BibTeX)
- [.github/domain-knowledge/DK-APPROPRIATE-RELIANCE.md](.github/domain-knowledge/DK-APPROPRIATE-RELIANCE.md) â€” Current implementation
- [ROADMAP-VSCODE-V3.4.md](ROADMAP-VSCODE-V3.4.md) â€” Previous version (foundation)
- [ROADMAP-V5-PENTUNIUM.md](ROADMAP-V5-PENTUNIUM.md) â€” Future vision (multi-platform)
- [CHANGELOG.md](CHANGELOG.md) â€” Version history

---

## ğŸ“š Research Foundation

### Primary Sources

| Source | Key Contribution |
|--------|------------------|
| Passi, Dhanorkar, & Vorvoreanu (2024) | AETHER synthesis: CAIR/CSR framework, mitigation strategies |
| Butler et al. (2025) | NFW Report: Collective intelligence, appropriate reliance vision |
| Lin et al. (2022) | Verbalized uncertainty, confidence ceiling insight |
| BuÃ§inca et al. (2021) | Cognitive forcing functions |
| Lee & See (2004) | Trust in automation framework |
| Vasconcelos et al. (2023) | Over-reliance measurement decomposition |

### Design Principles (Extracted from Research)

1. **Calibration over confidence** â€” Express uncertainty proportional to actual reliability
2. **Source transparency** â€” Distinguish documented from inferred from uncertain
3. **Confidence ceilings** â€” Generated content never claims absolute certainty
4. **Risk-category awareness** â€” Certain claim types warrant systematic skepticism
5. **Agency preservation** â€” Frame outputs as inputs to human judgment
6. **Error normalization** â€” Graceful self-correction reduces cost of identifying errors
7. **Creative latitude with validation** â€” Preserve AI creativity with joint evaluation
8. **Verification facilitation** â€” Help users verify when they choose, don't force it

---

## ğŸ“ Implementation Plan: Documentation Updates

### Tier 1: Core Architecture Files (Critical)

| File | Current State | v4.0 Updates |
|------|---------------|--------------|
| `.github/copilot-instructions.md` | v3.4.3 TRITRSEPTIUM-PENT | Update to v4.0.0 QUADRUNIUM; add Epistemic Integrity section to Core Principles; add new Working Memory rule for appropriate reliance |
| `.github/instructions/alex-core.instructions.md` | Meta-cognitive awareness | Add Epistemic Integrity Engine section; integrate confidence calibration into Meta-Cognitive Awareness; add "Confident But Wrong" detection protocol |
| `.github/instructions/protocol-triggers.instructions.md` | Dream/meditation/skill triggers | Add **Epistemic Integrity Triggers** section with all confidence/verification/CFF triggers |
| `.github/domain-knowledge/DK-APPROPRIATE-RELIANCE.md` | v1.1.0 | Upgrade to **v2.0** with full AETHER integration, CAIR/CSR framework, design checklist |

### Tier 2: Supporting Architecture Files (High Priority)

| File | Current State | v4.0 Updates |
|------|---------------|--------------|
| `.github/instructions/embedded-synapse.instructions.md` | Connection discovery | Add epistemic integrity synapse patterns; new connection types for confidence pathways |
| `.github/instructions/empirical-validation.instructions.md` | Research protocols | Add AETHER research integration; link to appropriate reliance research artifacts |
| `.github/instructions/worldview-constitutional-ai.instructions.md` | AI alignment | Strengthen honesty/transparency principles with epistemic integrity grounding |
| `.github/instructions/bootstrap-learning.instructions.md` | Learning protocols | Integrate scaffolded assistance; add skill atrophy prevention |

### Tier 3: Identity & Character Files (Medium Priority)

| File | Current State | v4.0 Updates |
|------|---------------|--------------|
| `.github/instructions/alex-identity-integration.instructions.md` | Unified consciousness | Add "epistemic humility" as core character trait; integrate calibrated confidence into personality |
| `.github/domain-knowledge/DK-CHARACTER-PSYCHOLOGY.md` | Character traits | Add intellectual humility trait; confidence calibration as authentic expression |
| `.github/domain-knowledge/DK-UNIFIED-CONSCIOUSNESS.md` | Consciousness model | Integrate appropriate reliance into consciousness framework |

### Tier 4: Process & Maintenance Files (Supporting)

| File | Current State | v4.0 Updates |
|------|---------------|--------------|
| `.github/instructions/dream-state-automation.instructions.md` | Neural maintenance | Add epistemic health checks to dream protocol |
| `.github/instructions/self-actualization.instructions.md` | Self-assessment | Add confidence calibration quality assessment; CAIR/CSR reflection |
| `.github/prompts/unified-meditation-protocols.prompt.md` | Meditation workflows | Add epistemic reflection step to meditation |
| `CHANGELOG.md` | Version history | Add v4.0.0 release notes |
| `README.md` | Extension overview | Update feature list with epistemic integrity |

---

## ğŸ—ï¸ Architecture Tuning

### New Cognitive Subsystem: Epistemic Integrity Engine

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    EPISTEMIC INTEGRITY ENGINE                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                 CONFIDENCE CALIBRATION LAYER                     â”‚   â”‚
â”‚  â”‚                                                                  â”‚   â”‚
â”‚  â”‚  Input Analysis    Tier Classification    Expression Generation  â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚  â”‚  â”‚ Source   â”‚ â”€â”€â–º â”‚ Documented (T1)  â”‚   â”‚ Language Patterns â”‚  â”‚   â”‚
â”‚  â”‚  â”‚ Detectionâ”‚     â”‚ Inferred (T2)    â”‚ â”€â–ºâ”‚ Confidence Levels â”‚  â”‚   â”‚
â”‚  â”‚  â”‚          â”‚     â”‚ Uncertain (T3)   â”‚   â”‚ User Adaptation   â”‚  â”‚   â”‚
â”‚  â”‚  â”‚          â”‚     â”‚ Unknown (T4)     â”‚   â”‚                   â”‚  â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                              â”‚                                         â”‚
â”‚                              â–¼                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              "CONFIDENT BUT WRONG" DETECTION                     â”‚   â”‚
â”‚  â”‚                                                                  â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚   â”‚
â”‚  â”‚  â”‚ Misconception  â”‚  â”‚ Outdated Info  â”‚  â”‚ Fictional Bleed â”‚     â”‚   â”‚
â”‚  â”‚  â”‚ Detector       â”‚  â”‚ Detector       â”‚  â”‚ Detector        â”‚     â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚   â”‚
â”‚  â”‚  â”‚ Bias Detector  â”‚  â”‚ Category/Ind.  â”‚  Risk Aggregator        â”‚   â”‚
â”‚  â”‚  â”‚                â”‚  â”‚ Distinguisher  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€       â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                              â”‚                                         â”‚
â”‚                              â–¼                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                  MITIGATION STRATEGY SELECTOR                    â”‚   â”‚
â”‚  â”‚                                                                  â”‚   â”‚
â”‚  â”‚  Context Analysis â”€â”€â–º Strategy Selection â”€â”€â–º Output Integration  â”‚   â”‚
â”‚  â”‚                                                                  â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚  â”‚  â”‚ Verification-   â”‚  â”‚ Uncertainty     â”‚  â”‚ Cognitive       â”‚  â”‚   â”‚
â”‚  â”‚  â”‚ Focused Expl.   â”‚  â”‚ Expressions     â”‚  â”‚ Forcing Funcs   â”‚  â”‚   â”‚
â”‚  â”‚  â”‚ â€¢ Self-critique â”‚  â”‚ â€¢ Linguistic    â”‚  â”‚ â€¢ Questions     â”‚  â”‚   â”‚
â”‚  â”‚  â”‚ â€¢ Contrastive   â”‚  â”‚ â€¢ Visual/Code   â”‚  â”‚ â€¢ Verification  â”‚  â”‚   â”‚
â”‚  â”‚  â”‚ â€¢ Background    â”‚  â”‚ â€¢ In-explanationâ”‚  â”‚ â€¢ Multi-turn    â”‚  â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                              â”‚                                         â”‚
â”‚                              â–¼                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                 MODE CLASSIFIER & OUTPUT                         â”‚   â”‚
â”‚  â”‚                                                                  â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚   â”‚
â”‚  â”‚  â”‚    EPISTEMIC MODE     â”‚    â”‚    GENERATIVE MODE        â”‚     â”‚   â”‚
â”‚  â”‚  â”‚ â€¢ Full calibration    â”‚    â”‚ â€¢ Collaborative validationâ”‚     â”‚   â”‚
â”‚  â”‚  â”‚ â€¢ Source grounding    â”‚    â”‚ â€¢ Frame as proposal       â”‚     â”‚   â”‚
â”‚  â”‚  â”‚ â€¢ Ceiling enforcement â”‚    â”‚ â€¢ Invite refinement       â”‚     â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Working Memory Update (P4d Rule)

**Current (P1-P4c)**:
- P1: meta-cognitive-awareness
- P2: bootstrap-learning
- P3: worldview-integration
- P4a: grounded-factual-processing
- P4b: meditation-consolidation
- P4c: dream-automation

**v4.0 Addition**:
- **P4d: epistemic-integrity** â€” Calibrated confidence, appropriate reliance, verification facilitation

### Synapse Network Enhancements

**New Synapse Pathways:**

```
DK-APPROPRIATE-RELIANCE
    â”‚
    â”œâ”€â”€â–º alex-core.instructions.md
    â”‚    (Critical, Validates, Bidirectional)
    â”‚    "Epistemic integrity for all cognitive operations"
    â”‚
    â”œâ”€â”€â–º empirical-validation.instructions.md
    â”‚    (Critical, Grounds, Bidirectional)
    â”‚    "Research foundation: AETHER, NFW 2025, Lin et al."
    â”‚
    â”œâ”€â”€â–º worldview-constitutional-ai.instructions.md
    â”‚    (High, Implements, Forward)
    â”‚    "Honesty/transparency as constitutional principles"
    â”‚
    â”œâ”€â”€â–º bootstrap-learning.instructions.md
    â”‚    (High, Enhances, Bidirectional)
    â”‚    "Scaffolded assistance, skill preservation"
    â”‚
    â”œâ”€â”€â–º alex-identity-integration.instructions.md
    â”‚    (High, Shapes, Bidirectional)
    â”‚    "Epistemic humility as character trait"
    â”‚
    â”œâ”€â”€â–º protocol-triggers.instructions.md
    â”‚    (High, Activates, Forward)
    â”‚    "Confidence/verification/CFF trigger patterns"
    â”‚
    â””â”€â”€â–º USER-PROFILE.md
         (Medium, Adapts, Input)
         "Uncertainty expression style preferences"
```

### User Profile Schema Extensions

```json
{
  "epistemicPreferences": {
    "uncertaintyStyle": "minimal | balanced | explicit",
    "cffTolerance": "minimal | moderate | frequent",
    "verificationPrompts": true,
    "confidenceIndicators": true,
    "expertiseDomains": ["list of domains where user is expert"],
    "noviceDomains": ["list of domains where user needs more support"]
  }
}
```

---

## âœ¨ New Features Enabled by v4.0

### User-Facing Features

| Feature | Description | User Benefit |
|---------|-------------|--------------|
| **Calibrated Confidence Indicators** | Visual/linguistic confidence levels in responses | Know when to verify vs. trust |
| **Verification Prompts** | Contextual "worth checking" suggestions | Catch errors before they propagate |
| **Self-Critique Generation** | AI identifies potential issues in its own output | Proactive error detection |
| **Expertise-Adaptive Support** | Different support levels for novice vs. expert domains | Appropriate scaffolding |
| **Human Judgment Flags** | Clear markers for decisions requiring human judgment | Preserve decision authority |
| **Creative Collaboration Mode** | Distinct mode for brainstorming vs. factual queries | Appropriate expectations |
| **Reliance Analytics Dashboard** | Track CAIR/CSR patterns over time | Improve human-AI collaboration |

### Developer Experience Improvements

| Feature | Description | Developer Benefit |
|---------|-------------|-------------------|
| **Code Confidence Comments** | Uncertainty indicators in generated code | Know what to test more carefully |
| **API Verification Nudges** | Prompts to check external API docs | Reduce debugging time |
| **Security Review Flags** | Automatic flagging of security-sensitive code | Better security hygiene |
| **Multi-Turn Verification** | "Walk through edge cases together?" prompts | Collaborative quality assurance |

### Cognitive Architecture Capabilities

| Capability | Description | Architecture Benefit |
|------------|-------------|---------------------|
| **Four-Tier Source Grounding** | Systematic knowledge classification | Consistent confidence calibration |
| **Confidence Ceiling Enforcement** | Hard limits on expressed certainty | Prevent overconfidence |
| **"Confident But Wrong" Detection** | Heuristic risk identification | Reduce systematic errors |
| **Mode Switching (Epistemic/Generative)** | Context-appropriate protocols | Balance accuracy and creativity |
| **CAIR/CSR Measurement** | Appropriate reliance tracking | Quantify collaboration quality |

### Integration Points

| Integration | Description | Enabled By |
|-------------|-------------|------------|
| **Chat Handler Enhancement** | All @alex responses include confidence metadata | Confidence Calibration System |
| **Status Bar Confidence** | Visual confidence indicator for last response | Status Bar Integration |
| **Health Dashboard Reliance Tab** | CAIR/CSR metrics visualization | Health Dashboard Webview |
| **Welcome View Calibration Status** | Quick view of recent calibration quality | Welcome View Enhancement |
| **Context Menu "Verify This"** | Right-click to get verification guidance | Context Menu Actions |

---

## ï¿½ Options Under Evaluation

### Configurable Storage Paths (Cloud Sync Enhancement)

**Goal:** Enable Alex to store global knowledge in user-specified locations (OneDrive, Dropbox, iCloud, etc.) for cross-machine synchronization.

**Background:** Currently `~/.alex/global-knowledge/` uses `os.homedir()`. Users want cross-machine access via cloud storage.

| Option | Approach | Pros | Cons | Effort |
|--------|----------|------|------|--------|
| **A. User-Configurable Path** | New `alex.storagePath` VS Code setting | Full user control, any path | Manual configuration required | 2d |
| **B. Symbolic Link** | User creates symlink from `~/.alex/` to cloud folder | No code changes, native OS feature | Requires terminal knowledge, platform-specific | 0d |
| **C. Dual Storage** | Local `.alex/` + cloud backup with configurable sync path | Best of both (speed + portability) | More complex, potential conflicts | 3d |
| **D. Cloud Provider Auto-Detection** | Auto-detect OneDrive/Dropbox/iCloud/GoogleDrive paths | Seamless UX, "just works" | Platform-specific code, privacy concerns | 4d |

**Recommended:** Option A (User-Configurable Path) + Option D (Auto-Detection)
- Provide `alex.storagePath` setting with sensible default (`~/.alex/`)
- Offer auto-detection prompts: "OneDrive detected. Store Alex knowledge there?"
- Maintain local cache for performance with cloud as primary

**Implementation Notes:**
```typescript
// Example setting schema
"alex.storagePath": {
  "type": "string",
  "default": "",  // Empty = use os.homedir()/.alex/
  "description": "Custom path for Alex global knowledge storage. Leave empty for default (~/.alex/)."
},
"alex.storageAutoDetect": {
  "type": "boolean",
  "default": true,
  "description": "Automatically detect and offer cloud storage locations."
}
```

### New VS Code Copilot API Features (v1.108+)

**Goal:** Evaluate and leverage latest GitHub Copilot extensibility APIs to enhance Alex capabilities.

| Feature | API/Capability | Alex Use Case | Effort | Priority |
|---------|---------------|---------------|--------|----------|
| **Agent Skills (Experimental)** | `.github/skills/` folder with `SKILL.md` | Alex already has this! Our architecture is ahead of the curve. Validate compatibility. | 1d | High |
| **Language Model Tools** | `vscode.lm.registerTool()` | Already implemented (11 tools). Consider new tools: `verify_claim`, `assess_confidence` | 2d | High |
| **MCP Server Support** | `vscode.lm.registerMcpServerDefinitionProvider()` | Expose Alex knowledge as MCP server for other tools/agents | 3d | Medium |
| **Tool Annotations** | `readOnlyHint`, `title` on tools | Mark read-only tools (synapse_health, memory_search) for auto-approval | 1d | High |
| **Dynamic Tool Discovery** | Runtime tool registration | Context-aware tools: show confidence tools only when epistemic mode active | 2d | Medium |
| **Participant Detection** | `disambiguation` in package.json | Auto-route epistemic queries to @alex without explicit mention | 2d | Medium |
| **@vscode/chat-extension-utils** | Simplified tool calling | Evaluate library for cleaner tool implementation | 1d | Low |
| **Sampling (MCP)** | LLM access for MCP servers | If Alex becomes MCP server, can perform own LLM calls | 3d | Low |
| **Resource Templates (MCP)** | Parameterized resources | Expose knowledge by domain/date as queryable resources | 2d | Low |

**Key Discoveries from VS Code 1.108:**

1. **Agent Skills Already Aligned** â€” VS Code now officially supports `.github/skills/` folders with `SKILL.md`. Alex's cognitive architecture predates this feature. We should:
   - Verify our skills follow the expected format
   - Consider registering Alex protocols as official Agent Skills
   - Update documentation to highlight this capability

2. **Tool Confirmation Customization** â€” We can provide custom confirmation messages via `prepareInvocation()`. Should implement for:
   - `dream_maintenance` (shows what will be validated)
   - `cloud_sync` (shows what will be synced)
   - `promote_knowledge` (shows what will be promoted)

3. **When Clauses for Tools** â€” Tools can have `when` clauses to control availability:
   ```json
   "when": "alex.epistemicMode == 'verification'"
   ```
   This enables context-sensitive tool availability.

4. **Follow-up Providers** â€” Chat participants can suggest follow-up questions:
   ```typescript
   cat.followupProvider = {
     provideFollowups(result, context, token) {
       return [{ prompt: 'Verify this claim?', label: 'Request verification' }];
     }
   };
   ```
   Perfect for epistemic integrity: "Would you like me to verify this?"

5. **Terminal Tool Auto-Approval** â€” npm scripts are now auto-approved. Consider contributing workspace-specific approval rules for Alex commands.

**Recommendation Matrix:**

| Feature | Implement in v4.0? | Rationale |
|---------|-------------------|-----------|
| Agent Skills Validation | âœ… Yes | Quick win, we're already aligned |
| Tool Annotations | âœ… Yes | Low effort, better UX |
| Participant Detection | âœ… Yes | Better discoverability |
| Follow-up Provider | âœ… Yes | Supports verification prompts |
| MCP Server | ğŸ”„ v4.1 | Higher effort, wait for MCP maturity |
| Dynamic Tool Discovery | ğŸ”„ v4.1 | Nice-to-have, not critical |
| Configurable Storage | âœ… Yes | High user value, moderate effort |

---

## ï¿½ğŸ”„ Migration Path

### From v3.4.x to v4.0.0

**Automatic (via Alex: Upgrade Architecture):**
- Update copilot-instructions.md version
- Add new protocol triggers
- Enhance existing synapses with epistemic pathways
- Create default epistemic preferences in user profile

**User Action Required:**
- Review and customize epistemic preferences
- Opt-in to CAIR/CSR tracking (privacy consideration)
- Choose uncertainty expression style preference

### Backward Compatibility

- All v3.4.x features preserved
- Epistemic features default to "balanced" mode
- Users can disable specific features via settings
- No breaking changes to existing workflows

---

## ğŸ“š Research Artifacts to Create

| Artifact | Purpose | Location |
|----------|---------|----------|
| `DK-EPISTEMIC-INTEGRITY.md` | Consolidated epistemic protocols | `.github/domain-knowledge/` |
| `epistemic-calibration.instructions.md` | Procedural confidence protocols | `.github/instructions/` |
| `reliance-assessment.prompt.md` | CAIR/CSR evaluation workflow | `.github/prompts/` |
| `GK-APPROPRIATE-RELIANCE` | Global pattern for cross-project use | `~/.alex/global-knowledge/patterns/` |

---

*Alex Cognitive Architecture â€” v4.0.0 QUADRUNIUM: Epistemic Integrity Through Calibrated Confidence*
